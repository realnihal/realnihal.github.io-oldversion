I"Ãq<h2 id="context-and-dataset-information">Context and Dataset information</h2>

<p>It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.</p>

<p>The dataset that we are using is obtained from the <a href="https://www.kaggle.com/mlg-ulb/creditcardfraud"><strong>Kaggle dataset by the Machine Learning Group - ULB</strong></a>.</p>

<p>The dataset that we are using contains transactions made by credit cards in September 2013 by European cardholders.
This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. <strong>This dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions</strong>.
It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, they cannot provide the original features and more background information about the data. Features V1, V2, ‚Ä¶ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are ‚ÄòTime‚Äô and ‚ÄòAmount‚Äô. Feature ‚ÄòTime‚Äô contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature ‚ÄòAmount‚Äô is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. <strong>Feature ‚ÄòClass‚Äô is the response variable and it takes value 1 in case of fraud and 0 otherwise</strong>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">Class</span><span class="p">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0    284315
1       492
Name: Class, dtype: int64
</code></pre></div></div>

<p>This is interesting! the dataset is imbalanced. 
In classification machine learning problems(binary and multiclass), datasets are often imbalanced which means that one class has a higher number of samples than others. This will lead to bias during the training of the model, the class containing a higher number of samples will be preferred more over the classes containing a lower number of samples. Having bias will, in turn, increase the true-negative and false-positive rates (ie, the precision and recall).</p>

<p>Let‚Äôs see the results without adjusting for the imbalanced bias on a base-model. I have used a <strong>simple logistic regression model</strong> for this.</p>

<h2 id="base-model">Base-Model</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">log_class</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">grid</span> <span class="o">=</span> <span class="p">{</span><span class="s">'C'</span><span class="p">:</span> <span class="mf">10.0</span> <span class="o">**</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="s">'penalty'</span><span class="p">:</span> <span class="p">[</span><span class="s">'l1'</span><span class="p">,</span> <span class="s">'l2'</span><span class="p">]}</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">log_class</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s">'f1_macro'</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>
<p>Let‚Äôs find the confusion matrix and the accuracy.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    [[198952     69]
     [   111    233]]

    0.9990971333985403
</code></pre></div></div>
<p>Looks like we got an accuracy of over 99 percent! But wait a minute we have an issue. The confusion matrix looks off‚Ä¶ lets look at the classification report.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                  precision    recall  f1-score   support
    
               0       1.00      1.00      1.00    199021
               1       0.77      0.68      0.72       344
    
        accuracy                           1.00    199365
       macro avg       0.89      0.84      0.86    199365
    weighted avg       1.00      1.00      1.00    199365
</code></pre></div></div>

<p>The precision of the failed cases is about 77 percent, not bad but I guess we can do better. Lets try a more complex model</p>

<h2 id="randomforestclassifier">RandomForestClassifier</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[199006     15]
 [    94    250]]
0.9994532641135605
</code></pre></div></div>

<p>Looks like we got an accuracy of over 99 percent! But the recall is still too high. We can do better!</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                  precision    recall  f1-score   support
    
               0       1.00      1.00      1.00    199021
               1       0.94      0.73      0.82       344
    
        accuracy                           1.00    199365
       macro avg       0.97      0.86      0.91    199365
    weighted avg       1.00      1.00      1.00    199365
</code></pre></div></div>
<p>Imbalanced datasets create a big problem. Like in our case if the minority class is just 0.17% of the majority. The model might resort to simplifying it as just ‚Äúone‚Äù class and inturn get great accuracy. In other words the model constantly guesses that there is no fraud and get away with it. To prevent this we need to artificial increase the importance of the minority. This is done predominantly by 2 methods:</p>

<ol>
  <li><strong>UnderSampling</strong> - We reduce the number of entries in the majority class by deleting them randomly, to make the overall ratio better.</li>
  <li><strong>OverSampling</strong> - We increase the entried in the minority by duplicating them without replacement. This also makes the overall ratio better.</li>
</ol>

<p>Let‚Äôs try a method called <a href="https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/"><strong>undersampling</strong></a>.</p>

<h2 id="under-sampling">Under-Sampling</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">NearMiss</span>
<span class="n">ns</span> <span class="o">=</span> <span class="n">NearMiss</span><span class="p">(</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">X_train_ns</span><span class="p">,</span> <span class="n">y_train_ns</span> <span class="o">=</span> <span class="n">ns</span><span class="p">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"The number of classes before fit {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_train</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"The number of classes after fit {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_train_ns</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The number of classes before fit Counter({0: 85294, 1: 148})
The number of classes after fit Counter({0: 185, 1: 148}) ```
</code></pre></div></div>

<p>Now we have equalized the classes, lets see if our model performs any better.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_ns</span><span class="p">,</span> <span class="n">y_train_ns</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[177877  21144]
 [    26    318]]
0.8938128558172197


              precision    recall  f1-score   support

           0       1.00      0.89      0.94    199021
           1       0.01      0.92      0.03       344

    accuracy                           0.89    199365
   macro avg       0.51      0.91      0.49    199365
weighted avg       1.00      0.89      0.94    199365
</code></pre></div></div>

<p>We have improved our recall, but our precision is dismal. this is a true disaster. Let‚Äôs try <a href="https://analyticsindiamag.com/handling-imbalanced-datasets-a-guide-with-hands-on-implementation/"><strong>over-sampling</strong></a>.</p>

<h2 id="over-sampling">Over-Sampling</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">RandomOverSampler</span>
<span class="n">os</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">X_train_os</span><span class="p">,</span> <span class="n">y_train_os</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"The number of classes before fit {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_train</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"The number of classes after fit {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_train_os</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The number of classes before fit Counter({0: 85294, 1: 148})
The number of classes after fit Counter({0: 85294, 1: 42647})
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">os</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">X_train_os</span><span class="p">,</span> <span class="n">y_train_os</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_os</span><span class="p">,</span> <span class="n">y_train_os</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[199004     17]
 [    81    263]]
0.9995084392947609
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    199021
           1       0.94      0.76      0.84       344

    accuracy                           1.00    199365
   macro avg       0.97      0.88      0.92    199365
weighted avg       1.00      1.00      1.00    199365
</code></pre></div></div>

<p>That looks a little better! a good precision with a decent recall. Lets try a <a href="https://imbalanced-learn.org/dev/references/generated/imblearn.combine.SMOTETomek.html"><strong>SMOTETomek model</strong></a>.</p>

<h2 id="smotetomek">SMOTETomek</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">imblearn.combine</span> <span class="kn">import</span> <span class="n">SMOTETomek</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">os</span> <span class="o">=</span> <span class="n">SMOTETomek</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">X_train_os</span><span class="p">,</span> <span class="n">y_train_os</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"The number of classes before fit {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_train</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"The number of classes after fit {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_train_os</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The number of classes before fit Counter({0: 85294, 1: 148})
The number of classes after fit Counter({0: 84204, 1: 41557})
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_os</span><span class="p">,</span> <span class="n">y_train_os</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[198975     46]
 [    62    282]]
0.9994582800391242
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    199021
           1       0.86      0.82      0.84       344

    accuracy                           1.00    199365
   macro avg       0.93      0.91      0.92    199365
weighted avg       1.00      1.00      1.00    199365
</code></pre></div></div>

<p>Wow that‚Äôs improved the recall a lot but the precision has dropped. I‚Äôm guessing that‚Äôs because of the part undersampling that the SMOTETomek model does. Why not try just the <a href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html"><strong>SMOTE model</strong></a>.</p>

<h2 id="smote">SMOTE</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sm</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">()</span>
<span class="n">X_train_sm</span><span class="p">,</span> <span class="n">y_train_sm</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"The number of classes before fit {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_train</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"The number of classes after fit {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">y_train_sm</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The number of classes before fit Counter({0: 85294, 1: 148})
The number of classes after fit Counter({0: 84230, 1: 41583})
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">clfsm</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">clfsm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_sm</span><span class="p">,</span> <span class="n">y_train_sm</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[198976     45]
 [    55    289]]
0.9994984074436335
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    199021
           1       0.87      0.84      0.85       344

    accuracy                           1.00    199365
   macro avg       0.93      0.92      0.93    199365
weighted avg       1.00      1.00      1.00    199365
</code></pre></div></div>

<p>Yes! we got slightly better results on both the precision and recall metrics. There is just one more model i wanted to try out, thats the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"><strong>Extra-Trees Classifier</strong></a>.</p>

<h2 id="extra-trees-classifier">Extra-Trees Classifier</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="n">clfsm</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">()</span>
<span class="n">clfsm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_sm</span><span class="p">,</span> <span class="n">y_train_sm</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prediction</span> <span class="o">=</span> <span class="n">clfsm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[198977     44]
 [    55    289]]
0.9995034233691972
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    199021
           1       0.87      0.84      0.85       344

    accuracy                           1.00    199365
   macro avg       0.93      0.92      0.93    199365
weighted avg       1.00      1.00      1.00    199365
</code></pre></div></div>

<p>The results of the ExtraTrees and SMOTE model look quite simliar.. thats interesting</p>

<h2 id="conclusions">Conclusions</h2>

<p>We have tried to solve our problem of data imbalance using multiple approaches. The best model that we could produce was between the extra-trees and the SMOTE model. Further attempts could be made with other models.</p>

<p>To check out the complete code for the project <a href="https://github.com/realnihal/Credit-Card-Fraud-Problem"><strong>click here</strong></a>.</p>
:ET